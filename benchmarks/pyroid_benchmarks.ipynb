{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyroid Performance Benchmarks\n",
    "\n",
    "This notebook demonstrates the performance advantages of Pyroid compared to pure Python implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up matplotlib style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Try to import pyroid\n",
    "try:\n",
    "    import pyroid\n",
    "    PYROID_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Warning: pyroid not found. Please install pyroid to run benchmarks.\")\n",
    "    PYROID_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(func, *args, **kwargs):\n",
    "    \"\"\"Simple benchmarking function.\"\"\"\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    duration_ms = (end_time - start_time) * 1000\n",
    "    return result, duration_ms\n",
    "\n",
    "def plot_comparison(title, results):\n",
    "    \"\"\"Plot a comparison of benchmark results.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    names = list(results.keys())\n",
    "    durations = [results[name] for name in names]\n",
    "    \n",
    "    # Set colors based on implementation\n",
    "    colors = []\n",
    "    for name in names:\n",
    "        if \"Python\" in name:\n",
    "            colors.append(\"#1f77b4\")  # Blue\n",
    "        elif \"NumPy\" in name:\n",
    "            colors.append(\"#ff7f0e\")  # Orange\n",
    "        elif \"pyroid\" in name:\n",
    "            colors.append(\"#2ca02c\")  # Green\n",
    "        else:\n",
    "            colors.append(\"#d62728\")  # Red\n",
    "    \n",
    "    bars = plt.bar(names, durations, color=colors)\n",
    "    \n",
    "    # Add duration labels on top of bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01 * max(durations),\n",
    "                f\"{height:.1f}ms\",\n",
    "                ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    # Add speedup labels for pyroid\n",
    "    if \"Pure Python\" in results and \"pyroid\" in results:\n",
    "        speedup = results[\"Pure Python\"] / results[\"pyroid\"]\n",
    "        plt.text(names.index(\"pyroid\"), results[\"pyroid\"] / 2,\n",
    "                f\"{speedup:.1f}x faster\",\n",
    "                ha='center', va='center', color='white', fontweight='bold')\n",
    "    \n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.ylabel(\"Time (ms)\", fontsize=12)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Math Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sum_benchmark(size=1_000_000):\n",
    "    \"\"\"Benchmark summing a large list of numbers.\"\"\"\n",
    "    print(f\"Generating {size:,} random numbers...\")\n",
    "    numbers = [random.random() for _ in range(size)]\n",
    "    print(\"Data generation complete.\\n\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Pure Python sum\n",
    "    print(\"Running Pure Python sum...\")\n",
    "    python_result, python_duration = benchmark(sum, numbers)\n",
    "    print(f\"Result: {python_result}\")\n",
    "    print(f\"Time: {python_duration:.2f}ms\")\n",
    "    results[\"Pure Python\"] = python_duration\n",
    "    \n",
    "    # NumPy sum\n",
    "    print(\"\\nRunning NumPy sum...\")\n",
    "    numpy_result, numpy_duration = benchmark(np.sum, numbers)\n",
    "    print(f\"Result: {numpy_result}\")\n",
    "    print(f\"Time: {numpy_duration:.2f}ms\")\n",
    "    results[\"NumPy\"] = numpy_duration\n",
    "    \n",
    "    # pyroid sum\n",
    "    if PYROID_AVAILABLE:\n",
    "        print(\"\\nRunning pyroid parallel_sum...\")\n",
    "        pyroid_result, pyroid_duration = benchmark(pyroid.parallel_sum, numbers)\n",
    "        print(f\"Result: {pyroid_result}\")\n",
    "        print(f\"Time: {pyroid_duration:.2f}ms\")\n",
    "        results[\"pyroid\"] = pyroid_duration\n",
    "        \n",
    "        # Calculate speedups\n",
    "        print(f\"\\nSpeedup vs Python: {python_duration / pyroid_duration:.1f}x\")\n",
    "        print(f\"Speedup vs NumPy: {numpy_duration / pyroid_duration:.1f}x\")\n",
    "    \n",
    "    # Plot the results\n",
    "    plot_comparison(f\"Sum {size:,} Numbers\", results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the benchmark\n",
    "sum_results = run_sum_benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. String Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regex_benchmark(size=100_000):\n",
    "    \"\"\"Benchmark regex replacement on a large text.\"\"\"\n",
    "    print(f\"Generating text with {size:,} repetitions...\")\n",
    "    text = \"Hello world! \" * size\n",
    "    print(f\"Text length: {len(text):,} characters\")\n",
    "    print(\"Data generation complete.\\n\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Pure Python regex\n",
    "    print(\"Running Pure Python regex replacement...\")\n",
    "    python_result, python_duration = benchmark(lambda t: re.sub(r\"Hello\", \"Hi\", t), text)\n",
    "    print(f\"Result length: {len(python_result):,} characters\")\n",
    "    print(f\"Time: {python_duration:.2f}ms\")\n",
    "    results[\"Pure Python\"] = python_duration\n",
    "    \n",
    "    # pyroid regex\n",
    "    if PYROID_AVAILABLE:\n",
    "        print(\"\\nRunning pyroid parallel_regex_replace...\")\n",
    "        pyroid_result, pyroid_duration = benchmark(pyroid.parallel_regex_replace, text, r\"Hello\", \"Hi\")\n",
    "        print(f\"Result length: {len(pyroid_result):,} characters\")\n",
    "        print(f\"Time: {pyroid_duration:.2f}ms\")\n",
    "        results[\"pyroid\"] = pyroid_duration\n",
    "        \n",
    "        # Calculate speedup\n",
    "        print(f\"\\nSpeedup vs Python: {python_duration / pyroid_duration:.1f}x\")\n",
    "    \n",
    "    # Plot the results\n",
    "    plot_comparison(f\"Regex Replace {len(text):,} Characters\", results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the benchmark\n",
    "regex_results = run_regex_benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sort_benchmark(size=1_000_000):\n",
    "    \"\"\"Benchmark sorting a large list.\"\"\"\n",
    "    print(f\"Generating {size:,} random integers...\")\n",
    "    data = [random.randint(1, 1000000) for _ in range(size)]\n",
    "    print(\"Data generation complete.\\n\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Pure Python sort\n",
    "    print(\"Running Pure Python sort...\")\n",
    "    python_result, python_duration = benchmark(sorted, data)\n",
    "    print(f\"Result length: {len(python_result):,} items\")\n",
    "    print(f\"First 5 items: {python_result[:5]}\")\n",
    "    print(f\"Time: {python_duration:.2f}ms\")\n",
    "    results[\"Pure Python\"] = python_duration\n",
    "    \n",
    "    # pyroid sort\n",
    "    if PYROID_AVAILABLE:\n",
    "        print(\"\\nRunning pyroid parallel_sort...\")\n",
    "        pyroid_result, pyroid_duration = benchmark(lambda d: pyroid.parallel_sort(d, None, False), data)\n",
    "        print(f\"Result length: {len(pyroid_result):,} items\")\n",
    "        print(f\"First 5 items: {pyroid_result[:5]}\")\n",
    "        print(f\"Time: {pyroid_duration:.2f}ms\")\n",
    "        results[\"pyroid\"] = pyroid_duration\n",
    "        \n",
    "        # Calculate speedup\n",
    "        print(f\"\\nSpeedup vs Python: {python_duration / pyroid_duration:.1f}x\")\n",
    "    \n",
    "    # Plot the results\n",
    "    plot_comparison(f\"Sort {size:,} Items\", results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the benchmark\n",
    "sort_results = run_sort_benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Real-world Scenario: Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data_pipeline_benchmark(size=500_000):\n",
    "    \"\"\"Benchmark a data processing pipeline.\"\"\"\n",
    "    print(f\"Generating {size:,} records of test data...\")\n",
    "    data = [{\"id\": i, \"value\": random.random(), \"category\": random.choice([\"A\", \"B\", \"C\", \"D\"])} for i in range(size)]\n",
    "    print(\"Data generation complete.\\n\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Pure Python implementation\n",
    "    print(\"Running Pure Python data pipeline...\")\n",
    "    \n",
    "    def python_pipeline(data):\n",
    "        # Step 1: Filter records where value > 0.5\n",
    "        filtered = [item for item in data if item[\"value\"] > 0.5]\n",
    "        \n",
    "        # Step 2: Transform values (multiply by 10)\n",
    "        transformed = [{\"id\": item[\"id\"], \"value\": item[\"value\"] * 10, \"category\": item[\"category\"]} for item in filtered]\n",
    "        \n",
    "        # Step 3: Group by category\n",
    "        grouped = {}\n",
    "        for item in transformed:\n",
    "            category = item[\"category\"]\n",
    "            if category not in grouped:\n",
    "                grouped[category] = []\n",
    "            grouped[category].append(item)\n",
    "        \n",
    "        # Step 4: Aggregate\n",
    "        results = []\n",
    "        for category, items in grouped.items():\n",
    "            total = sum(item[\"value\"] for item in items)\n",
    "            count = len(items)\n",
    "            results.append({\"category\": category, \"total\": total, \"count\": count, \"average\": total / count})\n",
    "        \n",
    "        # Step 5: Sort by average\n",
    "        results.sort(key=lambda x: x[\"average\"], reverse=True)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    python_result, python_duration = benchmark(python_pipeline, data)\n",
    "    print(f\"Result: {len(python_result)} categories\")\n",
    "    print(f\"Time: {python_duration:.2f}ms\")\n",
    "    results[\"Pure Python\"] = python_duration\n",
    "    \n",
    "    # pyroid implementation\n",
    "    if PYROID_AVAILABLE:\n",
    "        print(\"\\nRunning pyroid data pipeline...\")\n",
    "        \n",
    "        def pyroid_pipeline(data):\n",
    "            # Step 1: Filter records where value > 0.5\n",
    "            filtered = pyroid.parallel_filter(data, lambda item: item[\"value\"] > 0.5)\n",
    "            \n",
    "            # Step 2: Transform values (multiply by 10)\n",
    "            transformed = pyroid.parallel_map(filtered, lambda item: {\"id\": item[\"id\"], \"value\": item[\"value\"] * 10, \"category\": item[\"category\"]})\n",
    "            \n",
    "            # Step 3: Group by category (still using Python as pyroid doesn't have a direct equivalent)\n",
    "            grouped = {}\n",
    "            for item in transformed:\n",
    "                category = item[\"category\"]\n",
    "                if category not in grouped:\n",
    "                    grouped[category] = []\n",
    "                grouped[category].append(item)\n",
    "            \n",
    "            # Step 4: Aggregate using pyroid for each group\n",
    "            results = []\n",
    "            for category, items in grouped.items():\n",
    "                values = pyroid.parallel_map(items, lambda item: item[\"value\"])\n",
    "                total = pyroid.parallel_sum(values)\n",
    "                count = len(items)\n",
    "                results.append({\"category\": category, \"total\": total, \"count\": count, \"average\": total / count})\n",
    "            \n",
    "            # Step 5: Sort by average\n",
    "            results = pyroid.parallel_sort(results, lambda x: x[\"average\"], True)\n",
    "            \n",
    "            return results\n",
    "        \n",
    "        pyroid_result, pyroid_duration = benchmark(pyroid_pipeline, data)\n",
    "        print(f\"Result: {len(pyroid_result)} categories\")\n",
    "        print(f\"Time: {pyroid_duration:.2f}ms\")\n",
    "        results[\"pyroid\"] = pyroid_duration\n",
    "        \n",
    "        # Calculate speedup\n",
    "        print(f\"\\nSpeedup vs Python: {python_duration / pyroid_duration:.1f}x\")\n",
    "    \n",
    "    # Plot the results\n",
    "    plot_comparison(f\"Data Processing Pipeline ({size:,} records)\", results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the benchmark\n",
    "pipeline_results = run_data_pipeline_benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Let's summarize the performance improvements provided by Pyroid across different operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all results\n",
    "all_results = {\n",
    "    \"Sum 1M Numbers\": sum_results,\n",
    "    \"Regex Replace\": regex_results,\n",
    "    \"Sort 1M Items\": sort_results,\n",
    "    \"Data Pipeline\": pipeline_results\n",
    "}\n",
    "\n",
    "# Calculate speedups\n",
    "speedups = {}\n",
    "for name, results in all_results.items():\n",
    "    if \"Pure Python\" in results and \"pyroid\" in results:\n",
    "        speedups[name] = results[\"Pure Python\"] / results[\"pyroid\"]\n",
    "\n",
    "# Create a bar chart of speedups\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(speedups.keys(), speedups.values(), color=\"#2ca02c\")\n",
    "\n",
    "# Add speedup labels on top of bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "            f\"{height:.1f}x\",\n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.title(\"Pyroid Speedup vs Pure Python\", fontsize=16)\n",
    "plt.ylabel(\"Speedup Factor (x)\", fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Pyroid significantly outperforms pure Python implementations across a variety of operations:\n",
    "\n",
    "1. **Math Operations**: Pyroid's parallel sum is much faster than Python's built-in sum function and even outperforms NumPy.\n",
    "2. **String Operations**: Pyroid's parallel regex replacement is significantly faster than Python's re.sub.\n",
    "3. **Data Operations**: Pyroid's parallel sort outperforms Python's built-in sorted function.\n",
    "4. **Real-world Scenarios**: In a data processing pipeline that combines multiple operations, Pyroid shows impressive performance gains.\n",
    "\n",
    "These benchmarks demonstrate that Pyroid is an excellent choice for performance-critical Python applications, especially those involving large datasets or CPU-intensive operations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
